{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb350f8",
   "metadata": {},
   "source": [
    "# Classification after Clustering with Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343614e",
   "metadata": {},
   "source": [
    "### Import CSV and Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78fb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47444ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2240, 22)\n"
     ]
    }
   ],
   "source": [
    "pd.pandas.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(r'./data/clustered_data.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197a505",
   "metadata": {},
   "source": [
    "**Split X and y**\n",
    "- Why do we split our data?\n",
    "> Training Dataset is the part of Original Dataset that we use to train our ML model. The model learns on this data by running the algorithm and maps a function F(x) where “x” in the independent variable (inputs) for “y” where “y” is the dependent variable(output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a0152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('cluster', axis = 1)\n",
    "y = df['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97d90c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Parental Status</th>\n",
       "      <th>Children</th>\n",
       "      <th>Income</th>\n",
       "      <th>Total_Spending</th>\n",
       "      <th>Days_as_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>Wines</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Meat</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Sweets</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Web</th>\n",
       "      <th>Catalog</th>\n",
       "      <th>Store</th>\n",
       "      <th>Discount Purchases</th>\n",
       "      <th>Total Promo</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>81</td>\n",
       "      <td>546</td>\n",
       "      <td>120.5</td>\n",
       "      <td>81</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>776.0</td>\n",
       "      <td>4499.0</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>49</td>\n",
       "      <td>127</td>\n",
       "      <td>111.0</td>\n",
       "      <td>21</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4326.0</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>4348.0</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61223.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>4568.0</td>\n",
       "      <td>46</td>\n",
       "      <td>709</td>\n",
       "      <td>43</td>\n",
       "      <td>182</td>\n",
       "      <td>42.0</td>\n",
       "      <td>81</td>\n",
       "      <td>126.5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64014.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>4206.0</td>\n",
       "      <td>56</td>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56981.0</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>91</td>\n",
       "      <td>908</td>\n",
       "      <td>48</td>\n",
       "      <td>217</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69245.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>8</td>\n",
       "      <td>428</td>\n",
       "      <td>30</td>\n",
       "      <td>214</td>\n",
       "      <td>80.0</td>\n",
       "      <td>30</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>52869.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>4809.0</td>\n",
       "      <td>40</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Education  Marital Status  Parental Status  Children   Income  \\\n",
       "0      65          2               0                0         0  58138.0   \n",
       "1      68          2               0                1         2  46344.0   \n",
       "2      57          2               1                0         0  71613.0   \n",
       "3      38          2               1                1         1  26646.0   \n",
       "4      41          4               1                1         1  58293.0   \n",
       "...   ...        ...             ...              ...       ...      ...   \n",
       "2235   55          2               1                1         1  61223.0   \n",
       "2236   76          4               1                1         3  64014.0   \n",
       "2237   41          2               0                0         0  56981.0   \n",
       "2238   66          3               1                1         1  69245.0   \n",
       "2239   68          4               1                1         2  52869.0   \n",
       "\n",
       "      Total_Spending  Days_as_Customer  Recency  Wines  Fruits  Meat   Fish  \\\n",
       "0             1617.0            4850.0       58    635      81   546  120.5   \n",
       "1               27.0            4300.0       38     11       1     6    2.0   \n",
       "2              776.0            4499.0       26    426      49   127  111.0   \n",
       "3               53.0            4326.0       26     11       4    20   10.0   \n",
       "4              422.0            4348.0       94    173      43   118   46.0   \n",
       "...              ...               ...      ...    ...     ...   ...    ...   \n",
       "2235          1341.0            4568.0       46    709      43   182   42.0   \n",
       "2236           444.0            4206.0       56    406       0    30    0.0   \n",
       "2237          1241.0            4342.0       91    908      48   217   32.0   \n",
       "2238           843.0            4343.0        8    428      30   214   80.0   \n",
       "2239           172.0            4809.0       40     84       3    61    2.0   \n",
       "\n",
       "      Sweets   Gold  Web  Catalog  Store  Discount Purchases  Total Promo  \\\n",
       "0         81   88.0    8       10      4                   3            0   \n",
       "1          1    6.0    1        1      2                   2            0   \n",
       "2         21   42.0    8        2     10                   1            0   \n",
       "3          3    5.0    2        0      4                   2            0   \n",
       "4         27   15.0    5        3      6                   5            0   \n",
       "...      ...    ...  ...      ...    ...                 ...          ...   \n",
       "2235      81  126.5    9        3      4                   2            0   \n",
       "2236       0    8.0    8        2      5                   7            1   \n",
       "2237      12   24.0    2        3     13                   1            1   \n",
       "2238      30   61.0    6        5     10                   2            0   \n",
       "2239       1   21.0    3        1      4                   3            0   \n",
       "\n",
       "      NumWebVisitsMonth  \n",
       "0                     7  \n",
       "1                     5  \n",
       "2                     4  \n",
       "3                     6  \n",
       "4                     5  \n",
       "...                 ...  \n",
       "2235                  5  \n",
       "2236                  7  \n",
       "2237                  6  \n",
       "2238                  3  \n",
       "2239                  7  \n",
       "\n",
       "[2240 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee6bd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       2\n",
       "       ..\n",
       "2235    2\n",
       "2236    2\n",
       "2237    0\n",
       "2238    0\n",
       "2239    1\n",
       "Name: cluster, Length: 2240, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b043ff0",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "- Why do we use Grid Search?\n",
    "\n",
    "`GridSearchCV` is a technique to search through the best parameter values from the given set of the grid of parameters. It is basically a cross-validation method. the model and the parameters are required to be fed in. Best parameter values are extracted and then the predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841981ad",
   "metadata": {},
   "source": [
    "## Select the best model\n",
    "- so here we have some list of the best classification algorithms we imported. Now we will compare each model's score and see which model is performing better than rest of the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e61e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "\n",
    "models = {\n",
    "    \"Support Vector Classifier\" : SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "    # \"CatBoosting Classifier\": CatBoostClassifier(verbose = False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "880d69b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([SVC(), RandomForestClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier(), LogisticRegression(), KNeighborsClassifier(), XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...), AdaBoostClassifier()])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb0dd365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report\n",
    "def evaluate_models(X, y, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "    It splits the data into Train Test split\n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    \n",
    "    # Separate dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    model_list = []\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "        \n",
    "        # Make Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        model_name = list(models.keys())[i]\n",
    "        \n",
    "        print(f'---- Score for --- {model_name} ----')\n",
    "        print(f'{score}')\n",
    "        model_list.append(model_name)\n",
    "        scores.append(score)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    report = pd.DataFrame()\n",
    "    report['Model Name'] = model_list\n",
    "    report['Score'] = scores\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe7074a",
   "metadata": {},
   "source": [
    "### Let's check the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c03854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Score for --- Support Vector Classifier ----\n",
      "0.7299107142857143\n",
      "---- Score for --- Random Forest ----\n",
      "0.96875\n",
      "---- Score for --- Decision Tree ----\n",
      "0.9464285714285714\n",
      "---- Score for --- Gradient Boosting ----\n",
      "0.9642857142857143\n",
      "---- Score for --- Logistic Regression ----\n",
      "0.8772321428571429\n",
      "---- Score for --- K-Neighbors Classifier ----\n",
      "0.8102678571428571\n",
      "---- Score for --- XGBClassifier ----\n",
      "0.9665178571428571\n",
      "---- Score for --- AdaBoost Classifier ----\n",
      "0.9441964285714286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluate_models(X, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84d4cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.729911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.810268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.877232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.944196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.966518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name     Score\n",
       "0  Support Vector Classifier  0.729911\n",
       "5     K-Neighbors Classifier  0.810268\n",
       "4        Logistic Regression  0.877232\n",
       "7        AdaBoost Classifier  0.944196\n",
       "2              Decision Tree  0.946429\n",
       "3          Gradient Boosting  0.964286\n",
       "6              XGBClassifier  0.966518\n",
       "1              Random Forest  0.968750"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.sort_values('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cea36e",
   "metadata": {},
   "source": [
    "- ### From the report above we can see that the Random Forest Classifier model performed the best, so we will continue training our model using Random Forest Classifier algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54a811",
   "metadata": {},
   "source": [
    "### Split into Train and test data\n",
    "\n",
    "- **Do you know why we split the train and test dataset?**\n",
    "> The train test split technique can be used for classification and regression problems to test machine learning algorithms. The procedure takes the given dataset and splits it into two subsets: ```Training data/train set:``` it is used to train the algorithm and fit the machine learning model\n",
    "then we have ```test data/test set``` which is basically a different data for which we know the values but this data was never shown to the model before. Thus if the model after training is performing good on test set as well then we can say that the Machine Learning model is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "745a2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc4bb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Parental Status</th>\n",
       "      <th>Children</th>\n",
       "      <th>Income</th>\n",
       "      <th>Total_Spending</th>\n",
       "      <th>Days_as_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>Wines</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Meat</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Sweets</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Web</th>\n",
       "      <th>Catalog</th>\n",
       "      <th>Store</th>\n",
       "      <th>Discount Purchases</th>\n",
       "      <th>Total Promo</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40464.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>4721.0</td>\n",
       "      <td>78</td>\n",
       "      <td>424</td>\n",
       "      <td>17</td>\n",
       "      <td>118</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47916.0</td>\n",
       "      <td>606.0</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>72</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14188.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4673.0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76653.0</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>4504.0</td>\n",
       "      <td>91</td>\n",
       "      <td>736</td>\n",
       "      <td>63</td>\n",
       "      <td>556</td>\n",
       "      <td>120.5</td>\n",
       "      <td>81</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65196.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>4526.0</td>\n",
       "      <td>34</td>\n",
       "      <td>743</td>\n",
       "      <td>19</td>\n",
       "      <td>181</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82584.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>4577.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1076</td>\n",
       "      <td>68</td>\n",
       "      <td>103</td>\n",
       "      <td>29.0</td>\n",
       "      <td>81</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50127.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4218.0</td>\n",
       "      <td>88</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63855.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>4692.0</td>\n",
       "      <td>28</td>\n",
       "      <td>359</td>\n",
       "      <td>35</td>\n",
       "      <td>314</td>\n",
       "      <td>93.0</td>\n",
       "      <td>81</td>\n",
       "      <td>89.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62637.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4307.0</td>\n",
       "      <td>76</td>\n",
       "      <td>104</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54162.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4655.0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Education  Marital Status  Parental Status  Children   Income  \\\n",
       "324    69          2               0                1         1  40464.0   \n",
       "96     62          2               0                1         1  47916.0   \n",
       "2104   50          0               1                0         0  14188.0   \n",
       "1259   53          2               1                0         0  76653.0   \n",
       "1061   64          2               1                1         2  65196.0   \n",
       "...   ...        ...             ...              ...       ...      ...   \n",
       "423    48          3               1                0         0  82584.0   \n",
       "1340   60          2               1                1         1  50127.0   \n",
       "755    44          1               1                0         0  63855.0   \n",
       "2138   68          3               0                1         1  62637.0   \n",
       "618    44          2               0                1         2  54162.0   \n",
       "\n",
       "      Total_Spending  Days_as_Customer  Recency  Wines  Fruits  Meat   Fish  \\\n",
       "324            630.0            4721.0       78    424      17   118    7.0   \n",
       "96             606.0            4771.0       72    505       0    26    0.0   \n",
       "2104            75.0            4673.0       40      2       7    11   16.0   \n",
       "1259          2279.0            4504.0       91    736      63   556  120.5   \n",
       "1061          1155.0            4526.0       34    743      19   181   12.0   \n",
       "...              ...               ...      ...    ...     ...   ...    ...   \n",
       "423           1435.0            4577.0       26   1076      68   103   29.0   \n",
       "1340           320.0            4218.0       88    274       0    21    4.0   \n",
       "755           1006.0            4692.0       28    359      35   314   93.0   \n",
       "2138           185.0            4307.0       76    104      12    48    4.0   \n",
       "618             42.0            4655.0       31      5       6    10    6.0   \n",
       "\n",
       "      Sweets   Gold  Web  Catalog  Store  Discount Purchases  Total Promo  \\\n",
       "324       23   41.0    8        2      8                   6            0   \n",
       "96         0   75.0    7        4      6                   5            1   \n",
       "2104      12   27.0    2        0      4                   1            0   \n",
       "1259      81  126.0    4        7     11                   1            2   \n",
       "1061       0  126.5    7        6     11                   2            1   \n",
       "...      ...    ...  ...      ...    ...                 ...          ...   \n",
       "423       81   68.0    3        4      8                   1            2   \n",
       "1340       6   15.0    5        1      6                   1            1   \n",
       "755       81   89.0    7        3     13                   1            0   \n",
       "2138      12    5.0    2        2      5                   1            0   \n",
       "618        5   10.0    1        0      3                   1            0   \n",
       "\n",
       "      NumWebVisitsMonth  \n",
       "324                   8  \n",
       "96                    6  \n",
       "2104                  6  \n",
       "1259                  2  \n",
       "1061                  5  \n",
       "...                 ...  \n",
       "423                   1  \n",
       "1340                  6  \n",
       "755                   4  \n",
       "2138                  2  \n",
       "618                   4  \n",
       "\n",
       "[448 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb32a9",
   "metadata": {},
   "source": [
    "### Let's do hyperparameter tuning\n",
    "- **And what's it actually?**\n",
    "\n",
    "> A Machine Learning model is defined as a mathematical model with a number of parameters that need to be learned from the data. By training a model with existing data, we are able to fit the model parameters. \n",
    "However, there is another kind of parameter, known as Hyperparameters, that cannot be directly learned from the regular training process. They are usually fixed before the actual training process begins. These parameters express important properties of the model such as its complexity or how fast it should learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1760e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Tuned Hpyerparameters :(best parameters) {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy : 0.9654051446444966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"bootstrap\": [True]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs = -1)\n",
    "\n",
    "rf_cv = GridSearchCV(estimator = rf, param_grid = params, scoring = 'accuracy', cv = 5, n_jobs = -1, verbose = 1)\n",
    "rf_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"Tuned Hpyerparameters :(best parameters)\", rf_cv.best_params_)\n",
    "print(\"Accuracy :\", rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465fa0e",
   "metadata": {},
   "source": [
    "### So we got our best parameters. Let's now train the model with those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f258ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = RandomForestClassifier(bootstrap = True, \n",
    "    max_depth = None, \n",
    "    max_features = 'log2', \n",
    "    min_samples_leaf = 1, \n",
    "    min_samples_split = 2, \n",
    "    n_estimators = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d469f1b",
   "metadata": {},
   "source": [
    "**Initialize model with best parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0996c",
   "metadata": {},
   "source": [
    "### Let's check the report now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5739905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Accuracy Score value: 0.9710\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       128\n",
      "           1       0.99      0.97      0.98       167\n",
      "           2       0.95      0.97      0.96       153\n",
      "\n",
      "    accuracy                           0.97       448\n",
      "   macro avg       0.97      0.97      0.97       448\n",
      "weighted avg       0.97      0.97      0.97       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = best_rf_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred)\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print('Accuracy Score value: {:.4f}'.format(score))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a17357",
   "metadata": {},
   "source": [
    "## Confusion matrix of the model\n",
    "- **What is confusion matrix ?**\n",
    "> The confusion matrix is a matrix used to determine the performance of the classification models for a given set of test data. It can only be determined if the true values for test data are known. The matrix itself can be easily understood, but the related terminologies may be confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38818bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2a9376a5330>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f8d91",
   "metadata": {},
   "source": [
    "- **Reports**\n",
    "\n",
    "**We can see, that the model performed pretty well.**\n",
    "- we have used Random Forest Classifier as it performed well than other models\n",
    "- We got a good accuracy while predicting the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41eb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
